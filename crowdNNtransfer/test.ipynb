{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "# Load pre-trained EfficientNet-B0\n",
    "weights = EfficientNet_B0_Weights.DEFAULT\n",
    "model = efficientnet_b0(weights=weights)\n",
    "\n",
    "# Modify the classifier for regression (outputting a single scalar)\n",
    "model.classifier[1] = nn.Sequential(\n",
    "    nn.Linear(model.classifier[1].in_features, 1),\n",
    "    # nn.ReLU()\n",
    ")\n",
    "\n",
    "# Optional: Freeze feature extractor layers (at first)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class CrowdDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.images_dir = os.path.join(data_dir, 'images')\n",
    "        self.label_path = os.path.join(data_dir, 'image_labels.txt')\n",
    "        self.transform = transform\n",
    "\n",
    "        self.samples = []\n",
    "        with open(self.label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split(',')\n",
    "                if len(parts) >= 2:\n",
    "                    image_id = parts[0]\n",
    "                    count = float(parts[1])\n",
    "                    if count > 1000:\n",
    "                        continue  # skip this image\n",
    "                    filename = image_id + '.jpg'\n",
    "                    self.samples.append((filename, count))\n",
    "        \n",
    "        print(\"Sample:\", filename, count)   # Make sure data loaded correctly\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename, count = self.samples[idx]\n",
    "        image_path = os.path.join(self.images_dir, filename)\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        count = torch.tensor(count, dtype=torch.float32)\n",
    "\n",
    "        return image, count\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    # transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Define paths to each data split\n",
    "base_dir = './jhu_crowd_v2.0'\n",
    "splits = {\n",
    "    'train': os.path.join(base_dir, 'train'),\n",
    "    'val': os.path.join(base_dir, 'val'),\n",
    "    'test': os.path.join(base_dir, 'test')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.MSELoss()  # or try MAE with nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 4380.jpg 153.0\n",
      "Sample: 4377.jpg 92.0\n",
      "Sample: 4378.jpg 112.0\n",
      "Total samples: 2102\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = CrowdDataset(splits['train'], transform=transform)\n",
    "val_dataset = CrowdDataset(splits['val'], transform=transform)\n",
    "test_dataset = CrowdDataset(splits['test'], transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "print(\"Total samples:\", len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pass Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([263, 345,  48,  19, 100,  25,  14, 204,  34, 167, 357,  59, 155,  18,\n",
      "         56, 168,  97, 304, 110, 173,  42,   8,  25, 360, 245, 135, 123,   3,\n",
      "         21,  16,  14, 173], dtype=torch.int32)\n",
      "Loss:  26824\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 76,  44,  15, 236, 559,  45,  19, 106,  66, 107, 190,  44, 237,   3,\n",
      "        107,  55,  49, 200, 147, 103,  82, 326, 123, 527, 128, 106, 938, 222,\n",
      "         13, 191,  69, 230], dtype=torch.int32)\n",
      "Loss:  63931\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 14, 488, 173, 203,  30, 152, 392,  18,  20, 229, 150, 280,  14,  39,\n",
      "        204,  19,  85,  11, 239, 183,  24,  31,  39, 268,  73,  54, 232, 316,\n",
      "        135, 583,  42, 238], dtype=torch.int32)\n",
      "Loss:  44844\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 42,  41,  42,  20, 121, 671, 409, 206, 105,  90, 539, 220,  17,  92,\n",
      "        194,  21, 201, 340,  51, 933,  20,  37, 292, 122, 264,  86, 186, 337,\n",
      "         43,  43, 181, 326], dtype=torch.int32)\n",
      "Loss:  80752\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([259,  53, 536,   8, 207,  17, 110,  25,  45, 355, 162, 229,  60, 137,\n",
      "         13, 244, 170,  17, 188,  51,  48,   7, 182,  41, 369, 453, 391,  47,\n",
      "         30,  16, 194,  23], dtype=torch.int32)\n",
      "Loss:  41949\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([309,  41, 330, 135,  36, 164, 171,  54,  58,  12, 625, 444, 182, 316,\n",
      "        281,  20,   4, 507,   8,  70,  83, 560, 423,  49,  61, 246,   8, 221,\n",
      "          3,  75, 164,  75], dtype=torch.int32)\n",
      "Loss:  62571\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 30, 183,  56, 128, 375,  56,  94, 209,  30,   8, 197, 914,  33,  36,\n",
      "        134,  43,  74,  36,  48,  95, 720,  19, 301,  45, 129, 124, 249,  33,\n",
      "        102, 111,  46, 245], dtype=torch.int32)\n",
      "Loss:  61151\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([148,  35,  32,  74, 565,  26, 118, 120, 316, 160,  19,  42,   1, 132,\n",
      "         27,  48,  37, 295,   9, 133,  26, 186, 211,  91,  87,  42,  98,  82,\n",
      "         45, 570, 694, 334], dtype=torch.int32)\n",
      "Loss:  52005\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 79,  55,  42, 591,  34, 892,   8, 421,   9,  68, 202, 164, 130,  70,\n",
      "         56,  25,  20, 179, 581,  65,  22, 381,  25, 605, 273, 402,  44,  19,\n",
      "         18,  12,  57, 282], dtype=torch.int32)\n",
      "Loss:  82520\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 20, 804, 109,  14,   9,  98, 180, 163, 175, 183, 134, 492,  47, 546,\n",
      "        222, 772,  60, 248,  62,  35, 303,  35, 258,  40,  22,  72,  55, 712,\n",
      "         40,  63,  49, 893], dtype=torch.int32)\n",
      "Loss:  110913\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([  4,  18, 154,  89,  26, 278,   6,  94,  59, 494, 813,  37,  20, 105,\n",
      "        254,  76,  95, 128,  49,  38, 147,  87,  62,   0,  39, 111,  71, 611,\n",
      "         89,  40,  10, 319], dtype=torch.int32)\n",
      "Loss:  52338\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([253, 179,  46, 434,  15, 185, 173,  27, 250, 247, 306, 728,  53, 276,\n",
      "         16,  43, 113,  26, 130, 108, 245,  50,  85,  46, 115,  38,  16, 249,\n",
      "         46,  10, 324,  38], dtype=torch.int32)\n",
      "Loss:  46243\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 31, 192,  63,  52, 227,  54,  19, 170,  21,  23,  34,  37, 216,  27,\n",
      "         28, 119, 499, 195,  14, 457, 116, 152,  73, 196, 737, 149, 110, 361,\n",
      "        262,  99,  15, 103], dtype=torch.int32)\n",
      "Loss:  49017\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([138,  75, 836, 197,  60, 329,  23,  15, 122,  97,  58,  50, 356,  67,\n",
      "          4,  97,  28, 220,  29,  27, 100, 145, 446,  87,  45,  35,  57,  37,\n",
      "        131, 175, 556,  99], dtype=torch.int32)\n",
      "Loss:  53371\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 13, 194,  77,  17,  18, 229,  58, 202, 107, 474,  20, 295, 418,  58,\n",
      "        988, 124,  41,  46, 586, 287, 317, 234,  69,  12, 324, 112, 132, 139,\n",
      "        273, 845,  31,  39], dtype=torch.int32)\n",
      "Loss:  98998\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 22, 656,  73, 295,  88,  75, 697, 307, 133,  48,  39, 429, 260,  84,\n",
      "        364, 308, 451,  16,  38,  95,  52, 146, 136, 807, 207, 145,  45, 861,\n",
      "        140,  93, 116,  49], dtype=torch.int32)\n",
      "Loss:  105744\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 42,  52, 213, 154,  55,  65,  57, 855, 687,  10, 117,  52,  97,  25,\n",
      "         57, 424, 189,  83, 139,  66,  40,  87, 244, 107,  56, 169, 767,  72,\n",
      "        880,  92,   0, 128], dtype=torch.int32)\n",
      "Loss:  95865\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([364,  69, 329, 155,  68, 227, 839,  79,  39, 277, 165,  15, 118,  22,\n",
      "        182,  27,  74,  31, 221, 128,  30, 129,  22, 302,  58,  28,  17,  86,\n",
      "        158, 103, 167, 298], dtype=torch.int32)\n",
      "Loss:  47965\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 63,  32,  68, 231, 221, 982, 191, 154,  48, 520,  80, 131, 275, 708,\n",
      "         43, 322,  59, 106, 466, 500,  11,  57, 179,  68,  39, 483, 135, 127,\n",
      "         45,  51,  57, 289], dtype=torch.int32)\n",
      "Loss:  93760\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([177, 232, 350, 321,  49,  27, 332, 203,  47, 114,  75,  62,  75,  19,\n",
      "          3,   5,  23,  59,  20, 279,  42,  59,  20,  54, 236,  35,  89, 125,\n",
      "        115, 390,  52,  31], dtype=torch.int32)\n",
      "Loss:  26116\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 52,  85, 125,  92, 150, 266, 169,  53,  20, 267, 130,  14, 279,  72,\n",
      "        523,   9,  18,   7, 518,  39,  46,  21, 103,  20,  63, 154, 291,  73,\n",
      "         58,  28,  66,  57], dtype=torch.int32)\n",
      "Loss:  31761\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 59, 286, 114, 939, 928, 632, 257, 155, 637,  54, 247,  51, 100, 185,\n",
      "         14, 178,  15, 232, 584, 132,  48,  64, 329,  23, 623,  49,  53, 310,\n",
      "        820, 141, 277,  61], dtype=torch.int32)\n",
      "Loss:  145874\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 39,  19,  74,  73,  45, 206, 183, 283,  32,  61,  24, 277, 244, 604,\n",
      "         11, 259,  57, 191, 158, 160, 119,  32,  54,  79, 113, 116,  39, 185,\n",
      "        362, 146,  98,  16], dtype=torch.int32)\n",
      "Loss:  33842\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([275,  82, 164,  31,  51,   7, 353, 104, 994,  59, 379,  41, 151,  52,\n",
      "         31,  33, 133, 924, 166, 143,  90,  85,  21,  16, 243,  65,  48, 579,\n",
      "         79,  65, 100,  77], dtype=torch.int32)\n",
      "Loss:  86711\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 58,  60, 141, 148, 115, 534,  30,   3, 198,  58, 187, 181,  42, 277,\n",
      "        613, 166,  63, 200, 345,  43, 115,  17,  24, 314,  83, 178,  65,  90,\n",
      "         73, 424, 489,  23], dtype=torch.int32)\n",
      "Loss:  52904\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([128,  32, 378,  14, 418, 134,  29,  25,  88,  22, 403, 180, 175,   9,\n",
      "        349,  76,  38,  98, 240,  65,  86,  21,  39,  46,  59, 357, 449,  14,\n",
      "         44, 549, 124,  45], dtype=torch.int32)\n",
      "Loss:  45429\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([ 56, 531,  95, 130, 105,  85,  49, 201, 158,  81,  35, 340,  20,  78,\n",
      "        233,  48, 116,  61, 811,  33,  33,  17, 115,  85,  16, 389,  47,  15,\n",
      "         62, 220, 388,  26], dtype=torch.int32)\n",
      "Loss:  51205\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([400, 639, 279,  35, 107, 121, 175, 152, 688,  63,  94,  39,  18,  27,\n",
      "        262, 161,  28,  27, 122, 371,  27, 154, 109, 209,  28, 401,  33, 371,\n",
      "         44,  59,  28,  73], dtype=torch.int32)\n",
      "Loss:  58029\n",
      "Prediction:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "Value:  tensor([498, 502,  32, 239, 123, 144, 149,  33,   7, 176,  58,  80,  95, 139,\n",
      "        149,  14, 266, 163,  16, 424, 276,  71, 122, 468,  70, 541,  27, 289,\n",
      "         22,  25,  48,  92], dtype=torch.int32)\n",
      "Loss:  53009\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# or model.train() if training\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# If using CUDA\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Make sure labels are float\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralnetworks/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralnetworks/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralnetworks/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralnetworks/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[2], line 35\u001b[0m, in \u001b[0;36mCrowdDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m filename, count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[idx]\n\u001b[1;32m     33\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages_dir, filename)\n\u001b[0;32m---> 35\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     37\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralnetworks/lib/python3.11/site-packages/PIL/Image.py:984\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    982\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m--> 984\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralnetworks/lib/python3.11/site-packages/PIL/ImageFile.py:300\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    299\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 300\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  # or model.train() if training\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    images = images.to(device)  # If using CUDA\n",
    "    labels = labels.float().to(device)  # Make sure labels are float\n",
    "\n",
    "    outputs = model(images)  # Shape: [batch_size, 1]\n",
    "    outputs = outputs.squeeze(1)  # Shape: [batch_size]\n",
    "\n",
    "    int_counts = outputs.int()  # predictions as ints\n",
    "    true_counts = labels.int()  # actual values as ints\n",
    "\n",
    "    loss = criterion(outputs, labels).round().int()\n",
    "\n",
    "    print(\"Prediction: \", int_counts)\n",
    "    print(\"Value: \", true_counts)\n",
    "    print(\"Loss: \", loss.item())\n",
    "\n",
    "    # If training:\n",
    "    # optimizer.zero_grad()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnetworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
